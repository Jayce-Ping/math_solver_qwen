# Inference configuration for math_solver_qwen
max_tokens: 4096
temperature: 0.7
top_p: 0.9
batch_size: 8
use_tool_calls: true

# Model loading configuration
model_path: "./models/vision_r1_3b"
max_model_len: 32768
gpu_memory_utilization: 0.9
device_cnt: 2
dtype: "auto"