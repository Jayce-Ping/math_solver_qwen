# Inference configuration for math_solver_qwen
max_tokens: 4096
temperature: 0.1
top_p: 0.9
batch_size: 4
use_tool_calls: false

# Model loading configuration
model_path: "./models/vision_r1_3b"
model_name: "vision_r1_3b"
# model_path: "./models/math_vision_3b"
# model_name: "math_vision_3b"
# model_path: "/data/yyf/model/Qwen2.5-VL-3B-Instruct"
# model_name: "Qwen2.5-VL-3B-Instruct"
devices: "-1"  # Use all available devices
tensor_parallel_size: 8
gpu_memory_utilization: 0.9
dtype: "auto"