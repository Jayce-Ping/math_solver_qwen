# Inference configuration for math_solver_qwen
max_tokens: 4096
temperature: 0.7
top_p: 0.9
batch_size: 8

# Model loading configuration
model_path: "./models/vision_r1_3b"
max_model_len: 32768
dtype: "bfloat16"
gpu_memory_utilization: 0.85
device_cnt: 2